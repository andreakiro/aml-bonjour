{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0bfb96",
   "metadata": {},
   "source": [
    "# AML — Task 1\n",
    "## Predict the age of a brain from MRI features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b7547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "774c3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import IsolationForest, GradientBoostingRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408a978",
   "metadata": {},
   "source": [
    "---\n",
    "## Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fad40",
   "metadata": {},
   "source": [
    "---\n",
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47110725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    X_train = pd.read_csv('data/X_train.csv').drop(columns=['id'])\n",
    "    y_train = pd.read_csv('data/y_train.csv').drop(columns=['id'])\n",
    "    X_test = pd.read_csv('data/X_test.csv').drop(columns=['id'])\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a816b",
   "metadata": {},
   "source": [
    "---\n",
    "### Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23120b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned):\n",
    "    X_train_cleaned.to_csv('data/X_train_cleaned.csv', index=False)\n",
    "    y_train_cleaned.to_csv('data/y_train_cleaned.csv', index=False)\n",
    "    X_test_cleaned.to_csv('data/X_test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f4de4",
   "metadata": {},
   "source": [
    "---\n",
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c789017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X_train, y_train, contamination='auto', verbose=1):\n",
    "    \"\"\"\n",
    "    Remove the ouliers from our dataset. Temporarily replace the nan values by \n",
    "    the median to perform the outlier detection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.df\n",
    "        The features (what we will use to see the outliers)\n",
    "    y_train : pd.df\n",
    "        The labels\n",
    "    contamination : int, optional\n",
    "        The percent of outliers found by the isolation forest if it is used.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    (pd.df, pd.df)\n",
    "        The data with the outliers rows removed\n",
    "    \"\"\"\n",
    "    # Save a mask of the imputed values to be able to redo the imputation once the outlier detection is done\n",
    "    X_train_null_mask = X_train.isna()\n",
    "    \n",
    "    # Need to impute nan values for the outlier detection to work (cannot deal with nan)\n",
    "    X_train_imputed = pd.DataFrame(SimpleImputer(strategy=\"median\", verbose=verbose).fit_transform(X_train))\n",
    "    \n",
    "#     clf = IsolationForest(contamination=contamination, random_state=0) # modify here\n",
    "    clf = LocalOutlierFactor(contamination=contamination) # modify here\n",
    "    outliers_mask = pd.Series(clf.fit_predict(X_train_imputed))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Detected {(outliers_mask == -1).sum()} outliers, out of {outliers_mask.shape[0]} samples ({100 * (outliers_mask == -1).sum() / outliers_mask.shape[0]:.2f}%).\")\n",
    "    \n",
    "    # Put back the nan values\n",
    "    # convert the null mask to np.array so it is correctly applied since X_train indexes have changed\n",
    "    X_train_no_outliers = X_train_imputed.mask(np.array(X_train_null_mask))\n",
    "    \n",
    "    # Remove outliers from the training set\n",
    "    X_train_no_outliers = X_train_no_outliers.loc[outliers_mask == 1, :]\n",
    "    y_train_no_outliers = y_train.loc[outliers_mask == 1, :]\n",
    "    \n",
    "    return (X_train_no_outliers, y_train_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615112e3",
   "metadata": {},
   "source": [
    "---\n",
    "### Data scaling\n",
    "Should be done as soon as possible because can have an effect (e.g. on distances for `KNNImputer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bde22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    # Do the scaling, saving the scaler to use it for X_test too. No need for imputation, just ignore nan values.\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "    # Cast X_test to np.array to avoid warning of model trained without feature names but X having some.\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(np.array(X_test)))\n",
    "    return (X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012dc74",
   "metadata": {},
   "source": [
    "---\n",
    "### Imputation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e213b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(X_train, X_test, method='knn'):\n",
    "    print(f\"For the train dataset, there are {np.array(X_train.isna()).sum().sum()} nan values, out of {X_train.shape[0]*X_train.shape[1]} ({100*np.array(X_train.isna()).sum().sum()/(X_train.shape[0]*X_train.shape[1]):.2f}%).\")\n",
    "    \n",
    "    imputer = None\n",
    "    if method == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=6, weights='uniform').fit(X_train)\n",
    "    elif method == 'iterative':\n",
    "        # Runs VERY slowly\n",
    "        imputer = IterativeImputer(random_state=0, max_iter=15, verbose=2).fit(X_train)\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(imputer.transform(X_train))\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test))\n",
    "    return (X_train_imputed, X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b71de",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905e22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    X_train_selected_features, X_test_selected_features = remove_constant_features(X_train, X_test)\n",
    "    X_train_selected_features, X_test_selected_features = remove_too_correlated_features(X_train_selected_features, X_test_selected_features)\n",
    "    X_train_selected_features, X_test_selected_features = remove_random_features(X_train_selected_features, y_train, X_test_selected_features, percentile=80)\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed739797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_features(X_train, X_test, verbose=1):\n",
    "    X_train_selected_features = X_train.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    X_test_selected_features = X_test.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of constant values ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%).\")\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9496408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_correlated_features(X_train, X_test, threshold=0.7, verbose=1):\n",
    "    X_train_corr_ = X_train.corr()\n",
    "\n",
    "    X_train_too_correlated = (X_train_corr_.mask(\n",
    "        np.tril(np.ones([len(X_train_corr_)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    \n",
    "    X_train_selected_features = X_train.loc[:, (~X_train_too_correlated)]\n",
    "    X_test_selected_features = X_test.loc[:, (~X_train_too_correlated)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of correlation with another feature > {threshold} ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%).\")\n",
    "\n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1347a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_features(X_train, y_train, X_test, Xtrm, Xtem, percentile=80, verbose=1):\n",
    "    selector = SelectPercentile(f_regression, percentile=percentile) # modify here\n",
    "    selector.fit(X_train, np.array(y_train).ravel())\n",
    "    X_train_selected_features = pd.DataFrame(selector.transform(X_train))\n",
    "    X_test_selected_features = pd.DataFrame(selector.transform(X_test))\n",
    "    Xtrm_selected_features = pd.DataFrame(selector.transform(Xtrm))\n",
    "    Xtem_selected_features = pd.DataFrame(selector.transform(Xtem))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of low correlation with target ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%).\")\n",
    "        \n",
    "    return X_train_selected_features, X_test_selected_features, Xtrm_selected_features, Xtem_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76713b",
   "metadata": {},
   "source": [
    "---\n",
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e953cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lasso(X_train, y_train):\n",
    "    lasso = Lasso(max_iter=100000)\n",
    "    gs_lasso_params = {\n",
    "        'alpha': np.logspace(-2, 0, 20),\n",
    "    }\n",
    "    gs_lasso = GridSearchCV(lasso, gs_lasso_params, cv=5, verbose=3)\n",
    "    gs_lasso.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"The best validation score obtained is {gs_lasso.best_score_:.5f} with\\n\\talpha: {gs_lasso.best_params_['alpha']}\")\n",
    "    \n",
    "    return gs_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32755f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_svr(X_train, y_train):\n",
    "    svr = SVR()\n",
    "    gs_svr_params = {\n",
    "        'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "        'C': np.logspace(-1, 2.2, 4),\n",
    "        'epsilon': np.logspace(-2, 1, 3),\n",
    "    }\n",
    "    gs_svr = GridSearchCV(svr, gs_svr_params, cv=5, verbose=3)\n",
    "    gs_svr.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\"\"The best validation score obtained is {gs_svr.best_score_:.5f} with\n",
    "    \\tkernel: {gs_svr.best_params_['kernel']}\n",
    "    \\tC: {gs_svr.best_params_['C']}\n",
    "    \\tepsilon: {gs_svr.best_params_['epsilon']}\"\"\")\n",
    "    \n",
    "    return gs_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e54c62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_gbr(X_train, y_train):\n",
    "#     gbr = GradientBoostingRegressor(random_state=0)\n",
    "#     gs_gbr_params = {\n",
    "#         \"learning_rate\": np.logspace(-3, -1, 3),\n",
    "#         \"n_estimators\": np.logspace(1, 3, 3),\n",
    "#         \"subsample\": [0.7, 1],\n",
    "#         \"max_depth\": [3, 4, 5],\n",
    "#     }\n",
    "#     gs_gbr = GridSearchCV(gbr, gs_gbr_params, cv=5, verbose=3, error_score='raise')\n",
    "#     gs_gbr.fit(X_train, y_train)\n",
    "#     return gs_gbr\n",
    "\n",
    "    params = {\n",
    "        \"loss\": \"squared_error\",\n",
    "        \"n_estimators\": 250,\n",
    "        \"learning_rate\": 0.025,\n",
    "        \"subsample\": 0.75,\n",
    "        \"max_depth\": 6,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"n_iter_no_change\": 100,\n",
    "        \"validation_fraction\": 0.1,\n",
    "        \"random_state\": 0, \n",
    "        \"verbose\": 1,\n",
    "    }\n",
    "\n",
    "    gbr = GradientBoostingRegressor(**params)\n",
    "    \n",
    "    # Get the validation score\n",
    "    gbr_cv_scores = cross_val_score(gbr, X_train, y_train, n_jobs=-1, verbose=3)\n",
    "    print(f\"\"\"Validation score obtained is {np.mean(gbr_cv_scores):.4f} with\n",
    "    \\t{params}\"\"\")\n",
    "    \n",
    "    # Fit model (because previous function does not return fitted model)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    test_score = np.zeros(gbr.n_estimators_, dtype=np.float64)\n",
    "    for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
    "        test_score[i] = gbr.loss_(y_test, y_pred)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(\"Deviance\")\n",
    "    plt.plot(\n",
    "        np.arange(gbr.n_estimators_),\n",
    "        gbr.train_score_,\n",
    "        \"b-\",\n",
    "        label=\"Training Set Deviance\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(gbr.n_estimators_), test_score, \"r-\", label=\"Test Set Deviance\"\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Boosting Iterations\")\n",
    "    plt.ylabel(\"Deviance\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc46d2",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(prediction, sub_id, basepath='submissions/task1-sub'):\n",
    "    result = prediction.copy()\n",
    "    result = result.rename(columns={0: 'y'})\n",
    "    result['id'] = range(0, len(result))\n",
    "    result = result[['id', 'y']]\n",
    "    result.to_csv(basepath + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1f3bc",
   "metadata": {},
   "source": [
    "---\n",
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0466f",
   "metadata": {},
   "source": [
    "---\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44968a0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"Loading raw data...\")\n",
    "# X_train, y_train, X_test = load_raw_data()\n",
    "\n",
    "# print(\"Removing outliers...\")\n",
    "# X_train_no_outliers, y_train_no_outliers = remove_outliers(X_train, y_train)\n",
    "\n",
    "# print(\"Scaling data...\")\n",
    "# X_train_scaled, X_test_scaled = scale(X_train_no_outliers, X_test)\n",
    "\n",
    "# print(\"Imputing nan values...\")\n",
    "# X_train_imputed, X_test_imputed = impute_values(X_train_scaled, X_test_scaled, method=knn')\n",
    "\n",
    "# print(\"Selecting features...\")\n",
    "# X_train_selected_features, X_test_selected_features = select_features(X_train_imputed, y_train_no_outliers, X_test_imputed)\n",
    "\n",
    "# print(\"Exporting clean data to csv...\")\n",
    "# X_train_cleaned, y_train_cleaned, X_test_cleaned = X_train_selected_features, y_train_no_outliers, X_test_selected_features\n",
    "# export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned)\n",
    "\n",
    "# print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3bf407c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Removing outliers...\n",
      "Detected 50 outliers, out of 1212 samples (4.13%).\n",
      "Scaling data...\n",
      "Selecting features...\n",
      "0 features removed because of constant values (0.00%)\n",
      "146 features removed because of correlation > 0.7 (17.55%)\n",
      "For the train dataset, there are 60781 nan values, out of 797132 (7.62%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoine/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 features removed because of low correlation with target (80.03%)\n",
      "Imputing nan values...\n",
      "For the train dataset, there are 12065 nan values, out of 159194 (7.58%).\n",
      "[IterativeImputer] Completing matrix with shape (1162, 137)\n",
      "[IterativeImputer] Ending imputation round 1/15, elapsed time 1.89\n",
      "[IterativeImputer] Change: 23.347691166114693, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 2/15, elapsed time 3.82\n",
      "[IterativeImputer] Change: 2.0044169947193318, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 3/15, elapsed time 5.95\n",
      "[IterativeImputer] Change: 0.3507866998585426, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 4/15, elapsed time 8.33\n",
      "[IterativeImputer] Change: 0.1477798955071734, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 5/15, elapsed time 10.45\n",
      "[IterativeImputer] Change: 0.08213196633380365, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 6/15, elapsed time 12.67\n",
      "[IterativeImputer] Change: 0.045762605835757274, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 7/15, elapsed time 14.64\n",
      "[IterativeImputer] Change: 0.025541635740883896, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 8/15, elapsed time 16.57\n",
      "[IterativeImputer] Change: 0.014267741341644519, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 9/15, elapsed time 18.53\n",
      "[IterativeImputer] Change: 0.007973268852482882, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (1162, 137)\n",
      "[IterativeImputer] Ending imputation round 1/9, elapsed time 0.04\n",
      "[IterativeImputer] Ending imputation round 2/9, elapsed time 0.07\n",
      "[IterativeImputer] Ending imputation round 3/9, elapsed time 0.11\n",
      "[IterativeImputer] Ending imputation round 4/9, elapsed time 0.14\n",
      "[IterativeImputer] Ending imputation round 5/9, elapsed time 0.19\n",
      "[IterativeImputer] Ending imputation round 6/9, elapsed time 0.24\n",
      "[IterativeImputer] Ending imputation round 7/9, elapsed time 0.28\n",
      "[IterativeImputer] Ending imputation round 8/9, elapsed time 0.32\n",
      "[IterativeImputer] Ending imputation round 9/9, elapsed time 0.35\n",
      "[IterativeImputer] Completing matrix with shape (776, 137)\n",
      "[IterativeImputer] Ending imputation round 1/9, elapsed time 0.03\n",
      "[IterativeImputer] Ending imputation round 2/9, elapsed time 0.05\n",
      "[IterativeImputer] Ending imputation round 3/9, elapsed time 0.08\n",
      "[IterativeImputer] Ending imputation round 4/9, elapsed time 0.12\n",
      "[IterativeImputer] Ending imputation round 5/9, elapsed time 0.15\n",
      "[IterativeImputer] Ending imputation round 6/9, elapsed time 0.18\n",
      "[IterativeImputer] Ending imputation round 7/9, elapsed time 0.21\n",
      "[IterativeImputer] Ending imputation round 8/9, elapsed time 0.23\n",
      "[IterativeImputer] Ending imputation round 9/9, elapsed time 0.26\n",
      "Exporting clean data to csv...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw data...\")\n",
    "X_train, y_train, X_test = load_raw_data()\n",
    "\n",
    "print(\"Removing outliers...\")\n",
    "X_train, y_train = remove_outliers(X_train, y_train)\n",
    "\n",
    "print(\"Scaling data...\")\n",
    "X_train, X_test = scale(X_train, X_test)\n",
    "\n",
    "print(\"Selecting features...\")\n",
    "X_train, X_test = remove_constant_features(X_train, X_test)\n",
    "X_train, X_test = remove_too_correlated_features(X_train, X_test)\n",
    "\n",
    "#TODO: Clean pipeline\n",
    "# If we want iterative imputation, and don't want to run it for one hour (should try at one point though), need to\n",
    "# do feature selection before we do imputation. Except biggest filter for feature selection is f_regression which\n",
    "# cannot deal with nan values. Therefore, intermediary dumb knn imputation was quickly/dirtily \n",
    "# implemented to see results.\n",
    "# Conclusion: we achieve ~same or better validation scores with a LOT less features, seems like an \n",
    "# interresting way forward (even though test scores are a bit lower once submitted, but to not \n",
    "# overfit on the public ones and fail on the secret ones, should only watch validation score)\n",
    "X_train_mask = X_train.isna()\n",
    "X_test_mask = X_test.isna()\n",
    "X_train, X_test = impute_values(X_train, X_test, method='knn')\n",
    "X_train, X_test, X_train_mask, X_test_mask = remove_random_features(X_train, y_train, X_test, X_train_mask, X_test_mask, percentile=20)\n",
    "X_train = X_train.mask(np.array(X_train_mask))\n",
    "X_test = X_test.mask(np.array(X_test_mask))\n",
    "\n",
    "print(\"Imputing nan values...\")\n",
    "X_train, X_test = impute_values(X_train, X_test, method='iterative')\n",
    "\n",
    "print(\"Exporting clean data to csv...\")\n",
    "export_to_csv(X_train, y_train, X_test)\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849332e",
   "metadata": {},
   "source": [
    "---\n",
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fdcf188",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........................alpha=0.01;, score=0.452 total time=   0.0s\n",
      "[CV 2/5] END ........................alpha=0.01;, score=0.436 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.01;, score=0.428 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.01;, score=0.498 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.01;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.012742749857031334;, score=0.454 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.012742749857031334;, score=0.438 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.012742749857031334;, score=0.429 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.012742749857031334;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.012742749857031334;, score=0.386 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.016237767391887217;, score=0.456 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.016237767391887217;, score=0.440 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.016237767391887217;, score=0.431 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.016237767391887217;, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.016237767391887217;, score=0.388 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.0206913808111479;, score=0.457 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.0206913808111479;, score=0.442 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.0206913808111479;, score=0.433 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.0206913808111479;, score=0.503 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.0206913808111479;, score=0.390 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.026366508987303583;, score=0.459 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.026366508987303583;, score=0.445 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.026366508987303583;, score=0.436 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.026366508987303583;, score=0.505 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.026366508987303583;, score=0.392 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.03359818286283781;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.03359818286283781;, score=0.447 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.03359818286283781;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.03359818286283781;, score=0.507 total time=   0.1s\n",
      "[CV 5/5] END .........alpha=0.03359818286283781;, score=0.395 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.04281332398719394;, score=0.465 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.04281332398719394;, score=0.450 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.04281332398719394;, score=0.441 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.04281332398719394;, score=0.509 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.04281332398719394;, score=0.397 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.0545559478116852;, score=0.467 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.0545559478116852;, score=0.453 total time=   0.1s\n",
      "[CV 3/5] END ..........alpha=0.0545559478116852;, score=0.443 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.0545559478116852;, score=0.510 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.0545559478116852;, score=0.400 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.06951927961775606;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.06951927961775606;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.06951927961775606;, score=0.444 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.06951927961775606;, score=0.510 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.06951927961775606;, score=0.402 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.08858667904100823;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.08858667904100823;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.08858667904100823;, score=0.444 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.08858667904100823;, score=0.507 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.08858667904100823;, score=0.403 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.11288378916846889;, score=0.470 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.11288378916846889;, score=0.453 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.11288378916846889;, score=0.443 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.11288378916846889;, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.11288378916846889;, score=0.401 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.14384498882876628;, score=0.470 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.14384498882876628;, score=0.448 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.14384498882876628;, score=0.440 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.14384498882876628;, score=0.494 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.14384498882876628;, score=0.398 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.18329807108324356;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.18329807108324356;, score=0.441 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.18329807108324356;, score=0.434 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.18329807108324356;, score=0.488 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.18329807108324356;, score=0.392 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.23357214690901212;, score=0.465 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.23357214690901212;, score=0.432 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.23357214690901212;, score=0.428 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.23357214690901212;, score=0.481 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.23357214690901212;, score=0.389 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.29763514416313175;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.29763514416313175;, score=0.419 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.29763514416313175;, score=0.421 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.29763514416313175;, score=0.471 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.29763514416313175;, score=0.384 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.37926901907322497;, score=0.461 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.37926901907322497;, score=0.403 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.37926901907322497;, score=0.413 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.37926901907322497;, score=0.457 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.37926901907322497;, score=0.374 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.4832930238571752;, score=0.458 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.4832930238571752;, score=0.396 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.4832930238571752;, score=0.404 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.4832930238571752;, score=0.444 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.4832930238571752;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.615848211066026;, score=0.449 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.615848211066026;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.615848211066026;, score=0.392 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.615848211066026;, score=0.435 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.615848211066026;, score=0.358 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.7847599703514611;, score=0.435 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.7847599703514611;, score=0.384 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.7847599703514611;, score=0.376 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.7847599703514611;, score=0.423 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.7847599703514611;, score=0.349 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=1.0;, score=0.414 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=1.0;, score=0.369 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=1.0;, score=0.352 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=1.0;, score=0.404 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=1.0;, score=0.334 total time=   0.0s\n",
      "The best validation score obtained is 0.45596 with\n",
      "\talpha: 0.06951927961775606\n"
     ]
    }
   ],
   "source": [
    "lasso = best_lasso(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "753572c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.084 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.054 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.045 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.051 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.021 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.131 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.106 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.104 total time=   0.3s\n",
      "[CV 4/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.118 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.112 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.323 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.283 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.246 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.270 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.085 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.050 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.045 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.050 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.129 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.106 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.101 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.119 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.112 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.321 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.281 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.249 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.271 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.249 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.042 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.052 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.036 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.037 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.018 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.060 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.062 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.064 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.065 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.071 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.220 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.193 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.191 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.187 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.201 total time=   0.0s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.308 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.161 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.163 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.181 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.138 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.460 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.389 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.364 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.412 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.416 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.308 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.360 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.268 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.413 total time=   0.2s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.258 total time=   0.2s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.310 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.159 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.166 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.181 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.137 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.461 total time=   0.2s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.388 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.367 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.413 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.415 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.308 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.344 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.262 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.416 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.265 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.180 total time=   0.0s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.127 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.112 total time=   0.0s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.109 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.065 total time=   0.0s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.293 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.307 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.340 total time=   0.0s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.333 total time=   0.0s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.343 total time=   0.0s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.330 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.365 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.312 total time=   0.0s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.482 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.363 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.406 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.386 total time=   0.2s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.368 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.612 total time=   0.2s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.517 total time=   0.2s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.508 total time=   0.2s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.559 total time=   0.2s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.567 total time=   0.2s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-50.577 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-80.875 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-29.330 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-19.189 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-36.311 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.479 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.361 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.402 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.383 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.364 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.612 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.517 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.510 total time=   0.2s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.558 total time=   0.2s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.567 total time=   0.2s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-49.875 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-81.417 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-29.613 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-18.860 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-36.474 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.260 total time=   0.0s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.121 total time=   0.0s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.186 total time=   0.0s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.121 total time=   0.0s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.439 total time=   0.0s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.371 total time=   0.0s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.443 total time=   0.0s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.403 total time=   0.0s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.460 total time=   0.0s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-36.281 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-60.253 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-22.571 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-14.755 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-27.586 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.344 total time=   0.3s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.039 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.327 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.276 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.253 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.566 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.499 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.521 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.546 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.587 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-7576.328 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-12679.697 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-4264.284 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-3047.998 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-5061.205 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.351 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.052 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.332 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.274 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.252 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.564 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.498 total time=   0.1s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.523 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.545 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.587 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-7548.272 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-5111.577 total time=   0.1s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-4229.185 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-2999.862 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-5039.680 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.219 total time=   0.0s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.022 total time=   0.0s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.158 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.059 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.136 total time=   0.0s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.420 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.377 total time=   0.0s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.440 total time=   0.0s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.391 total time=   0.0s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.456 total time=   0.0s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-7529.159 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-5314.672 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-4091.563 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-3055.399 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-4950.710 total time=   0.1s\n",
      "The best validation score obtained is 0.55284 with\n",
      "    \tkernel: rbf\n",
      "    \tC: 13.593563908785255\n",
      "    \tepsilon: 0.31622776601683794\n"
     ]
    }
   ],
   "source": [
    "svr = best_svr(X_train, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25f33dfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.9s remaining:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score obtained is 0.5904 with\n",
      "    \t{'loss': 'squared_error', 'n_estimators': 250, 'learning_rate': 0.025, 'subsample': 0.75, 'max_depth': 6, 'min_samples_split': 5, 'n_iter_no_change': 100, 'validation_fraction': 0.1, 'random_state': 0, 'verbose': 1}\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          91.3713           2.7151            8.69s\n",
      "         2          90.4951           2.4329            8.24s\n",
      "         3          87.5395           1.8259            8.23s\n",
      "         4          84.9354           1.7079            8.17s\n",
      "         5          81.1857           1.5119            8.14s\n",
      "         6          77.7074           1.7922            8.21s\n",
      "         7          78.0268           1.6303            8.35s\n",
      "         8          73.7842           1.7695           10.68s\n",
      "         9          72.9198           1.3300           10.44s\n",
      "        10          69.6703           1.6567           10.24s\n",
      "        20          49.8719           0.7727           10.13s\n",
      "        30          37.4365           0.6052            8.95s\n",
      "        40          28.4774           0.4223            8.19s\n",
      "        50          22.2246           0.2451            7.62s\n",
      "        60          17.3187           0.1576            7.18s\n",
      "        70          13.3941           0.1034            6.76s\n",
      "        80          10.6298           0.0306            6.32s\n",
      "        90           8.8260           0.0156            5.86s\n",
      "       100           7.0520           0.0228            5.44s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: could not manage to get grid search to work with this, should look into it as there are a lot of\n",
    "# hyperparameters at play\n",
    "gbr = best_gbr(X_train, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484e0aa",
   "metadata": {},
   "source": [
    "---\n",
    "### Creation of the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aeeb561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(gbr.predict(X_test)) # modify here\n",
    "sub_id = 13 # modify here\n",
    "create_submission(prediction, sub_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae690721",
   "metadata": {},
   "source": [
    "Link where to submit: https://aml.ise.inf.ethz.ch/task1/#submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

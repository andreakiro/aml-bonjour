{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0bfb96",
   "metadata": {},
   "source": [
    "# AML â€” Task 1\n",
    "## Predict the age of a brain from MRI features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b7547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774c3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import IsolationForest, GradientBoostingRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408a978",
   "metadata": {},
   "source": [
    "---\n",
    "## Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fad40",
   "metadata": {},
   "source": [
    "---\n",
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47110725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    X_train = pd.read_csv('data/X_train.csv').drop(columns=['id'])\n",
    "    y_train = pd.read_csv('data/y_train.csv').drop(columns=['id'])\n",
    "    X_test = pd.read_csv('data/X_test.csv').drop(columns=['id'])\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a816b",
   "metadata": {},
   "source": [
    "---\n",
    "### Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23120b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned):\n",
    "    X_train_cleaned.to_csv('data/X_train_cleaned.csv', index=False)\n",
    "    y_train_cleaned.to_csv('data/y_train_cleaned.csv', index=False)\n",
    "    X_test_cleaned.to_csv('data/X_test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f4de4",
   "metadata": {},
   "source": [
    "---\n",
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c789017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X_train, y_train, contamination='auto', verbose=1):\n",
    "    \"\"\"\n",
    "    Remove the ouliers from our dataset. Temporarily replace the nan values by \n",
    "    the median to perform the outlier detection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.df\n",
    "        The features (what we will use to see the outliers)\n",
    "    y_train : pd.df\n",
    "        The labels\n",
    "    contamination : int, optional\n",
    "        The percent of outliers found by the isolation forest if it is used.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    (pd.df, pd.df)\n",
    "        The data with the outliers rows removed\n",
    "    \"\"\"\n",
    "    # Save a mask of the imputed values to be able to redo the imputation once the outlier detection is done\n",
    "    X_train_null_mask = X_train.isna()\n",
    "    \n",
    "    # Need to impute nan values for the outlier detection to work (cannot deal with nan)\n",
    "    X_train_imputed = pd.DataFrame(SimpleImputer(strategy=\"median\", verbose=verbose).fit_transform(X_train))\n",
    "    \n",
    "#     clf = IsolationForest(contamination=contamination, random_state=0) # modify here\n",
    "    clf = LocalOutlierFactor(contamination=contamination) # modify here\n",
    "    outliers_mask = pd.Series(clf.fit_predict(X_train_imputed))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Detected {(outliers_mask == -1).sum()} outliers, out of {outliers_mask.shape[0]} samples ({100 * (outliers_mask == -1).sum() / outliers_mask.shape[0]:.2f}%).\")\n",
    "    \n",
    "    # Put back the nan values\n",
    "    # convert the null mask to np.array so it is correctly applied since X_train indexes have changed\n",
    "    X_train_no_outliers = X_train_imputed.mask(np.array(X_train_null_mask))\n",
    "    \n",
    "    # Remove outliers from the training set\n",
    "    X_train_no_outliers = X_train_no_outliers.loc[outliers_mask == 1, :]\n",
    "    y_train_no_outliers = y_train.loc[outliers_mask == 1, :]\n",
    "    \n",
    "    return (X_train_no_outliers, y_train_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615112e3",
   "metadata": {},
   "source": [
    "---\n",
    "### Data scaling\n",
    "Should be done as soon as possible because can have an effect (e.g. on distances for `KNNImputer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bde22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    # Do the scaling, saving the scaler to use it for X_test too. No need for imputation, just ignore nan values.\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "    # Cast X_test to np.array to avoid warning of model trained without feature names but X having some.\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(np.array(X_test)))\n",
    "    return (X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012dc74",
   "metadata": {},
   "source": [
    "---\n",
    "### Imputation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e213b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(X_train, X_test, method='knn'):\n",
    "    print(f\"For the train dataset, there are {np.array(X_train.isna()).sum().sum()} nan values, out of {X_train.shape[0]*X_train.shape[1]} ({100*np.array(X_train.isna()).sum().sum()/(X_train.shape[0]*X_train.shape[1]):.2f}%).\")\n",
    "    \n",
    "    imputer = None\n",
    "    if method == 'knn':\n",
    "        imputer = KNNImputer(n_neighbors=6, weights='uniform').fit(X_train)\n",
    "    elif method == 'iterative':\n",
    "        # Runs VERY slowly\n",
    "        imputer = IterativeImputer(random_state=0, verbose=2).fit(X_train)\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(imputer.transform(X_train))\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test))\n",
    "    return (X_train_imputed, X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b71de",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "905e22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    X_train_selected_features, X_test_selected_features = remove_constant_features(X_train, X_test)\n",
    "    X_train_selected_features, X_test_selected_features = remove_too_correlated_features(X_train_selected_features, X_test_selected_features)\n",
    "    X_train_selected_features, X_test_selected_features = remove_random_features(X_train_selected_features, y_train, X_test_selected_features, percentile=80)\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed739797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_features(X_train, X_test, verbose=1):\n",
    "    X_train_selected_features = X_train.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    X_test_selected_features = X_test.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of constant values ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9496408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_correlated_features(X_train, X_test, threshold=0.7, verbose=1):\n",
    "    X_train_corr_ = X_train.corr()\n",
    "\n",
    "    X_train_too_correlated = (X_train_corr_.mask(\n",
    "        np.tril(np.ones([len(X_train_corr_)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    \n",
    "    X_train_selected_features = X_train.loc[:, (~X_train_too_correlated)]\n",
    "    X_test_selected_features = X_test.loc[:, (~X_train_too_correlated)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of correlation > {threshold} ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "\n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1347a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_features(X_train, y_train, X_test, Xtrm, Xtem, percentile=80, verbose=1):\n",
    "    selector = SelectPercentile(f_regression, percentile=percentile) # modify here\n",
    "    selector.fit(X_train, np.array(y_train).ravel())\n",
    "    X_train_selected_features = pd.DataFrame(selector.transform(X_train))\n",
    "    X_test_selected_features = pd.DataFrame(selector.transform(X_test))\n",
    "    Xtrm_selected_features = pd.DataFrame(selector.transform(Xtrm))\n",
    "    Xtem_selected_features = pd.DataFrame(selector.transform(Xtem))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of low correlation with target ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "        \n",
    "    return X_train_selected_features, X_test_selected_features, Xtrm_selected_features, Xtem_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76713b",
   "metadata": {},
   "source": [
    "---\n",
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98e953cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lasso(X_train, y_train):\n",
    "    lasso = Lasso(max_iter=100000)\n",
    "    gs_lasso_params = {\n",
    "        'alpha': np.logspace(-2, 0, 20),\n",
    "    }\n",
    "    gs_lasso = GridSearchCV(lasso, gs_lasso_params, cv=5, verbose=3)\n",
    "    gs_lasso.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"The best validation score obtained is {gs_lasso.best_score_:.5f} with\\n\\talpha: {gs_lasso.best_params_['alpha']}\")\n",
    "    \n",
    "    return gs_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32755f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_svr(X_train, y_train):\n",
    "    svr = SVR()\n",
    "    gs_svr_params = {\n",
    "        'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "        'C': np.logspace(-1, 2.2, 4),\n",
    "        'epsilon': np.logspace(-2, 1, 3),\n",
    "    }\n",
    "    gs_svr = GridSearchCV(svr, gs_svr_params, cv=5, verbose=3)\n",
    "    gs_svr.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\"\"The best validation score obtained is {gs_svr.best_score_:.5f} with\n",
    "    \\tkernel: {gs_svr.best_params_['kernel']}\n",
    "    \\tC: {gs_svr.best_params_['C']}\n",
    "    \\tepsilon: {gs_svr.best_params_['epsilon']}\"\"\")\n",
    "    \n",
    "    return gs_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e54c62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_gbr(X_train, y_train):\n",
    "#     gbr = GradientBoostingRegressor(random_state=0)\n",
    "#     gs_gbr_params = {\n",
    "#         \"learning_rate\": np.logspace(-3, -1, 3),\n",
    "#         \"n_estimators\": np.logspace(1, 3, 3),\n",
    "#         \"subsample\": [0.7, 1],\n",
    "#         \"max_depth\": [3, 4, 5],\n",
    "#     }\n",
    "#     gs_gbr = GridSearchCV(gbr, gs_gbr_params, cv=5, verbose=3, error_score='raise')\n",
    "#     gs_gbr.fit(X_train, y_train)\n",
    "#     return gs_gbr\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"loss\": \"squared_error\",\n",
    "        \"random_state\": 0, \n",
    "        \"verbose\": 1,\n",
    "    }\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(**params)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Score is {gbr.score(X_test, y_test):.4f}.\")\n",
    "    \n",
    "    test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
    "        test_score[i] = gbr.loss_(y_test, y_pred)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(\"Deviance\")\n",
    "    plt.plot(\n",
    "        np.arange(params[\"n_estimators\"]) + 1,\n",
    "        gbr.train_score_,\n",
    "        \"b-\",\n",
    "        label=\"Training Set Deviance\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Boosting Iterations\")\n",
    "    plt.ylabel(\"Deviance\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc46d2",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd4ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(prediction, sub_id, basepath='submissions/task1-sub'):\n",
    "    result = prediction.copy()\n",
    "    result = result.rename(columns={0: 'y'})\n",
    "    result['id'] = range(0, len(result))\n",
    "    result = result[['id', 'y']]\n",
    "    result.to_csv(basepath + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1f3bc",
   "metadata": {},
   "source": [
    "---\n",
    "##Â Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0466f",
   "metadata": {},
   "source": [
    "---\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44968a0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"Loading raw data...\")\n",
    "# X_train, y_train, X_test = load_raw_data()\n",
    "\n",
    "# print(\"Removing outliers...\")\n",
    "# X_train_no_outliers, y_train_no_outliers = remove_outliers(X_train, y_train)\n",
    "\n",
    "# print(\"Scaling data...\")\n",
    "# X_train_scaled, X_test_scaled = scale(X_train_no_outliers, X_test)\n",
    "\n",
    "# print(\"Imputing nan values...\")\n",
    "# X_train_imputed, X_test_imputed = impute_values(X_train_scaled, X_test_scaled, method=knn')\n",
    "\n",
    "# print(\"Selecting features...\")\n",
    "# X_train_selected_features, X_test_selected_features = select_features(X_train_imputed, y_train_no_outliers, X_test_imputed)\n",
    "\n",
    "# print(\"Exporting clean data to csv...\")\n",
    "# X_train_cleaned, y_train_cleaned, X_test_cleaned = X_train_selected_features, y_train_no_outliers, X_test_selected_features\n",
    "# export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned)\n",
    "\n",
    "# print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3bf407c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Removing outliers...\n",
      "Detected 50 outliers, out of 1212 samples (4.13%).\n",
      "Scaling data...\n",
      "Selecting features...\n",
      "0 features removed because of constant values (0.00%)\n",
      "146 features removed because of correlation > 0.7 (17.55%)\n",
      "For the train dataset, there are 60781 nan values, out of 797132 (7.62%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoine/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 features removed because of low correlation with target (69.97%)\n",
      "Imputing nan values...\n",
      "For the train dataset, there are 18108 nan values, out of 239372 (7.56%).\n",
      "[IterativeImputer] Completing matrix with shape (1162, 206)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 5.68\n",
      "[IterativeImputer] Change: 24.54097752758862, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 11.38\n",
      "[IterativeImputer] Change: 1.8333972078591216, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 17.52\n",
      "[IterativeImputer] Change: 0.2782159738102602, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 23.12\n",
      "[IterativeImputer] Change: 0.13795426292901322, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 29.29\n",
      "[IterativeImputer] Change: 0.0684152493362627, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 35.38\n",
      "[IterativeImputer] Change: 0.033864580304978104, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 41.78\n",
      "[IterativeImputer] Change: 0.01676506519388638, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 48.18\n",
      "[IterativeImputer] Change: 0.008306150548468883, scaled tolerance: 0.013896992902987433 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (1162, 206)\n",
      "[IterativeImputer] Ending imputation round 1/8, elapsed time 0.09\n",
      "[IterativeImputer] Ending imputation round 2/8, elapsed time 0.19\n",
      "[IterativeImputer] Ending imputation round 3/8, elapsed time 0.31\n",
      "[IterativeImputer] Ending imputation round 4/8, elapsed time 0.44\n",
      "[IterativeImputer] Ending imputation round 5/8, elapsed time 0.61\n",
      "[IterativeImputer] Ending imputation round 6/8, elapsed time 0.78\n",
      "[IterativeImputer] Ending imputation round 7/8, elapsed time 0.95\n",
      "[IterativeImputer] Ending imputation round 8/8, elapsed time 1.09\n",
      "[IterativeImputer] Completing matrix with shape (776, 206)\n",
      "[IterativeImputer] Ending imputation round 1/8, elapsed time 0.14\n",
      "[IterativeImputer] Ending imputation round 2/8, elapsed time 0.25\n",
      "[IterativeImputer] Ending imputation round 3/8, elapsed time 0.36\n",
      "[IterativeImputer] Ending imputation round 4/8, elapsed time 0.48\n",
      "[IterativeImputer] Ending imputation round 5/8, elapsed time 0.58\n",
      "[IterativeImputer] Ending imputation round 6/8, elapsed time 0.68\n",
      "[IterativeImputer] Ending imputation round 7/8, elapsed time 0.78\n",
      "[IterativeImputer] Ending imputation round 8/8, elapsed time 0.87\n",
      "Exporting clean data to csv...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw data...\")\n",
    "X_train, y_train, X_test = load_raw_data()\n",
    "\n",
    "print(\"Removing outliers...\")\n",
    "X_train, y_train = remove_outliers(X_train, y_train)\n",
    "\n",
    "print(\"Scaling data...\")\n",
    "X_train, X_test = scale(X_train, X_test)\n",
    "\n",
    "print(\"Selecting features...\")\n",
    "X_train, X_test = remove_constant_features(X_train, X_test)\n",
    "X_train, X_test = remove_too_correlated_features(X_train, X_test)\n",
    "\n",
    "#TODO: Clean pipeline\n",
    "# If we want iterative imputation, and don't want to run it for one hour (should try at one point though), need to\n",
    "# do feature selection before we do imputation. Except biggest filter for feature selection is f_regression which\n",
    "# cannot deal with nan values. Therefore, intermediary dumb knn imputation was quickly/dirtily \n",
    "# implemented to see results.\n",
    "# Conclusion: we achieve ~same or better validation scores with a LOT less features, seems like an \n",
    "# interresting way forward (even though test scores are a bit lower once submitted, but to not \n",
    "# overfit on the public ones and fail on the secret ones, should only watch validation score)\n",
    "X_train_mask = X_train.isna()\n",
    "X_test_mask = X_test.isna()\n",
    "X_train, X_test = impute_values(X_train, X_test, method='knn')\n",
    "X_train, X_test, X_train_mask, X_test_mask = remove_random_features(X_train, y_train, X_test, X_train_mask, X_test_mask, percentile=30)\n",
    "X_train = X_train.mask(np.array(X_train_mask))\n",
    "X_test = X_test.mask(np.array(X_test_mask))\n",
    "\n",
    "print(\"Imputing nan values...\")\n",
    "X_train, X_test = impute_values(X_train, X_test, method='iterative')\n",
    "\n",
    "print(\"Exporting clean data to csv...\")\n",
    "export_to_csv(X_train, y_train, X_test)\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849332e",
   "metadata": {},
   "source": [
    "---\n",
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fdcf188",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........................alpha=0.01;, score=0.460 total time=   0.1s\n",
      "[CV 2/5] END ........................alpha=0.01;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END ........................alpha=0.01;, score=0.452 total time=   0.0s\n",
      "[CV 4/5] END ........................alpha=0.01;, score=0.460 total time=   0.0s\n",
      "[CV 5/5] END ........................alpha=0.01;, score=0.392 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.012742749857031334;, score=0.461 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.012742749857031334;, score=0.456 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.012742749857031334;, score=0.454 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.012742749857031334;, score=0.463 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.012742749857031334;, score=0.394 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.016237767391887217;, score=0.463 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.016237767391887217;, score=0.457 total time=   0.0s\n",
      "[CV 3/5] END ........alpha=0.016237767391887217;, score=0.456 total time=   0.0s\n",
      "[CV 4/5] END ........alpha=0.016237767391887217;, score=0.466 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.016237767391887217;, score=0.397 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.0206913808111479;, score=0.465 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.0206913808111479;, score=0.458 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.0206913808111479;, score=0.459 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.0206913808111479;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.0206913808111479;, score=0.401 total time=   0.0s\n",
      "[CV 1/5] END ........alpha=0.026366508987303583;, score=0.467 total time=   0.0s\n",
      "[CV 2/5] END ........alpha=0.026366508987303583;, score=0.459 total time=   0.1s\n",
      "[CV 3/5] END ........alpha=0.026366508987303583;, score=0.462 total time=   0.1s\n",
      "[CV 4/5] END ........alpha=0.026366508987303583;, score=0.475 total time=   0.0s\n",
      "[CV 5/5] END ........alpha=0.026366508987303583;, score=0.404 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.03359818286283781;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.03359818286283781;, score=0.459 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.03359818286283781;, score=0.465 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.03359818286283781;, score=0.480 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.03359818286283781;, score=0.408 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.04281332398719394;, score=0.471 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.04281332398719394;, score=0.460 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.04281332398719394;, score=0.468 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.04281332398719394;, score=0.486 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.04281332398719394;, score=0.412 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.0545559478116852;, score=0.475 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.0545559478116852;, score=0.461 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.0545559478116852;, score=0.471 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.0545559478116852;, score=0.491 total time=   0.1s\n",
      "[CV 5/5] END ..........alpha=0.0545559478116852;, score=0.416 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.06951927961775606;, score=0.477 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.06951927961775606;, score=0.461 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.06951927961775606;, score=0.473 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.06951927961775606;, score=0.493 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.06951927961775606;, score=0.418 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.08858667904100823;, score=0.478 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.08858667904100823;, score=0.459 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.08858667904100823;, score=0.471 total time=   0.1s\n",
      "[CV 4/5] END .........alpha=0.08858667904100823;, score=0.493 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.08858667904100823;, score=0.418 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.11288378916846889;, score=0.477 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.11288378916846889;, score=0.454 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.11288378916846889;, score=0.467 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.11288378916846889;, score=0.489 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.11288378916846889;, score=0.412 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.14384498882876628;, score=0.475 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.14384498882876628;, score=0.446 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.14384498882876628;, score=0.460 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.14384498882876628;, score=0.482 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.14384498882876628;, score=0.406 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.18329807108324356;, score=0.471 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.18329807108324356;, score=0.439 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.18329807108324356;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.18329807108324356;, score=0.477 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.18329807108324356;, score=0.398 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.23357214690901212;, score=0.466 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.23357214690901212;, score=0.431 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.23357214690901212;, score=0.441 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.23357214690901212;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.23357214690901212;, score=0.390 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.29763514416313175;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.29763514416313175;, score=0.419 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.29763514416313175;, score=0.429 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.29763514416313175;, score=0.456 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.29763514416313175;, score=0.380 total time=   0.0s\n",
      "[CV 1/5] END .........alpha=0.37926901907322497;, score=0.460 total time=   0.0s\n",
      "[CV 2/5] END .........alpha=0.37926901907322497;, score=0.405 total time=   0.0s\n",
      "[CV 3/5] END .........alpha=0.37926901907322497;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END .........alpha=0.37926901907322497;, score=0.446 total time=   0.0s\n",
      "[CV 5/5] END .........alpha=0.37926901907322497;, score=0.374 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.4832930238571752;, score=0.457 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.4832930238571752;, score=0.398 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.4832930238571752;, score=0.407 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.4832930238571752;, score=0.440 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.4832930238571752;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.615848211066026;, score=0.449 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.615848211066026;, score=0.393 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.615848211066026;, score=0.395 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.615848211066026;, score=0.435 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.615848211066026;, score=0.359 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.7847599703514611;, score=0.435 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.7847599703514611;, score=0.385 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.7847599703514611;, score=0.379 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.7847599703514611;, score=0.423 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.7847599703514611;, score=0.350 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=1.0;, score=0.413 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=1.0;, score=0.371 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=1.0;, score=0.355 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=1.0;, score=0.405 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=1.0;, score=0.335 total time=   0.0s\n",
      "The best validation score obtained is 0.46430 with\n",
      "\talpha: 0.06951927961775606\n"
     ]
    }
   ],
   "source": [
    "lasso = best_lasso(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "753572c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.045 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.037 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.028 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.030 total time=   0.1s\n",
      "[CV 5/5] END ..C=0.1, epsilon=0.01, kernel=poly;, score=0.010 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.098 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.076 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.078 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.089 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, epsilon=0.01, kernel=rbf;, score=0.077 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.271 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.239 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.214 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.229 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.01, kernel=sigmoid;, score=0.205 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.041 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.025 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.029 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=poly;, score=0.005 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.101 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.075 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.077 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.088 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=rbf;, score=0.076 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.271 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.239 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.216 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.205 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.010 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.027 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.018 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.015 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, epsilon=10.0, kernel=poly;, score=0.012 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.044 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.045 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.050 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.049 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, epsilon=10.0, kernel=rbf;, score=0.052 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.157 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.156 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, epsilon=10.0, kernel=sigmoid;, score=0.164 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.069 total time=   0.2s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.114 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.118 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=poly;, score=0.081 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.434 total time=   0.2s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.348 total time=   0.2s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.327 total time=   0.2s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.371 total time=   0.2s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=rbf;, score=0.344 total time=   0.2s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.401 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.423 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.367 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.456 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.01, kernel=sigmoid;, score=0.339 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.191 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.068 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.114 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.117 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=poly;, score=0.081 total time=   0.1s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.433 total time=   0.2s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.351 total time=   0.2s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.328 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.373 total time=   0.2s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=rbf;, score=0.345 total time=   0.2s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.403 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.420 total time=   0.1s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.370 total time=   0.1s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.452 total time=   0.1s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=0.31622776601683794, kernel=sigmoid;, score=0.342 total time=   0.2s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.106 total time=   0.1s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.084 total time=   0.0s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.070 total time=   0.0s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.074 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=poly;, score=0.050 total time=   0.0s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.294 total time=   0.0s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.242 total time=   0.0s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.258 total time=   0.0s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.262 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=rbf;, score=0.281 total time=   0.0s\n",
      "[CV 1/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.375 total time=   0.0s\n",
      "[CV 2/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.351 total time=   0.0s\n",
      "[CV 3/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.348 total time=   0.0s\n",
      "[CV 4/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.358 total time=   0.0s\n",
      "[CV 5/5] END C=1.1659144011798317, epsilon=10.0, kernel=sigmoid;, score=0.338 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.426 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.296 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.318 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=poly;, score=0.287 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.607 total time=   0.2s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.497 total time=   0.2s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.506 total time=   0.2s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.533 total time=   0.2s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=rbf;, score=0.537 total time=   0.2s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-6.145 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-6.148 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-4.334 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-2.239 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.01, kernel=sigmoid;, score=-5.526 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.421 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.293 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.315 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.281 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=poly;, score=0.282 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.607 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.496 total time=   0.2s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.507 total time=   0.2s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.531 total time=   0.3s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=rbf;, score=0.537 total time=   0.2s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-6.196 total time=   0.2s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-11.159 total time=   0.2s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-4.205 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-2.386 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=0.31622776601683794, kernel=sigmoid;, score=-6.162 total time=   0.2s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.165 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.061 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.121 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.099 total time=   0.0s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=poly;, score=0.074 total time=   0.0s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.408 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.405 total time=   0.0s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.373 total time=   0.0s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=rbf;, score=0.414 total time=   0.1s\n",
      "[CV 1/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-3.515 total time=   0.1s\n",
      "[CV 2/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-6.186 total time=   0.1s\n",
      "[CV 3/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-2.366 total time=   0.1s\n",
      "[CV 4/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-1.170 total time=   0.1s\n",
      "[CV 5/5] END C=13.593563908785255, epsilon=10.0, kernel=sigmoid;, score=-3.424 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.293 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.061 total time=   0.1s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.262 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.250 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=poly;, score=0.129 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.566 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.450 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.546 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.524 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=rbf;, score=0.571 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-1374.133 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-2777.692 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-740.156 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-525.162 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.01, kernel=sigmoid;, score=-977.902 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.293 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.064 total time=   0.1s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.258 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.246 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=poly;, score=0.124 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.565 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.448 total time=   0.3s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.546 total time=   0.3s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.524 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=rbf;, score=0.570 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-1331.833 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-2876.701 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-747.546 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-529.495 total time=   0.2s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=0.31622776601683794, kernel=sigmoid;, score=-992.819 total time=   0.2s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.096 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=-0.099 total time=   0.1s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.114 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=0.050 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=poly;, score=-0.000 total time=   0.1s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.370 total time=   0.1s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.313 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.397 total time=   0.1s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.360 total time=   0.0s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=rbf;, score=0.395 total time=   0.0s\n",
      "[CV 1/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-1323.668 total time=   0.2s\n",
      "[CV 2/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-2825.587 total time=   0.2s\n",
      "[CV 3/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-737.958 total time=   0.2s\n",
      "[CV 4/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-525.466 total time=   0.1s\n",
      "[CV 5/5] END C=158.48931924611142, epsilon=10.0, kernel=sigmoid;, score=-915.087 total time=   0.2s\n",
      "The best validation score obtained is 0.53584 with\n",
      "    \tkernel: rbf\n",
      "    \tC: 13.593563908785255\n",
      "    \tepsilon: 0.01\n"
     ]
    }
   ],
   "source": [
    "svr = best_svr(X_train, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25f33dfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          96.1383           31.17s\n",
      "         2          95.0618           28.76s\n",
      "         3          94.0136           27.93s\n",
      "         4          92.9759           27.85s\n",
      "         5          91.9499           27.86s\n",
      "         6          90.9605           27.42s\n",
      "         7          89.9814           27.03s\n",
      "         8          89.0215           27.23s\n",
      "         9          88.0802           27.07s\n",
      "        10          87.1464           26.79s\n",
      "        20          78.7616           27.38s\n",
      "        30          71.5699           26.74s\n",
      "        40          65.4768           25.80s\n",
      "        50          60.1468           24.98s\n",
      "        60          55.4013           24.27s\n",
      "        70          51.1510           23.58s\n",
      "        80          47.4010           22.94s\n",
      "        90          44.0601           22.33s\n",
      "       100          41.0734           21.73s\n",
      "       200          23.7403           16.02s\n",
      "       300          15.9482           10.77s\n",
      "       400          11.3161            5.39s\n",
      "       500           8.5454            0.00s\n",
      "Score is 0.5755.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: could not manage to get CV to work with this, should look into it as there are a lot of\n",
    "# hyperparameters at play\n",
    "gbr = best_gbr(X_train, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484e0aa",
   "metadata": {},
   "source": [
    "---\n",
    "### Creation of the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aeeb561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(gbr.predict(X_test)) # modify here\n",
    "sub_id = 10 # modify here\n",
    "create_submission(prediction, sub_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae690721",
   "metadata": {},
   "source": [
    "Link where to submit: https://aml.ise.inf.ethz.ch/task1/#submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

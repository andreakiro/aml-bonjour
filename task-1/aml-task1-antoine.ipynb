{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaaed19e",
   "metadata": {},
   "source": [
    "# AML â€” Task 1\n",
    "## Predict the age of a brain from MRI features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57374ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98a0bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import IsolationForest, GradientBoostingRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c2a67",
   "metadata": {},
   "source": [
    "---\n",
    "## Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f1126",
   "metadata": {},
   "source": [
    "---\n",
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29a94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    X_train = pd.read_csv('data/X_train.csv').drop(columns=['id'])\n",
    "    y_train = pd.read_csv('data/y_train.csv').drop(columns=['id'])\n",
    "    X_test = pd.read_csv('data/X_test.csv').drop(columns=['id'])\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86358fe",
   "metadata": {},
   "source": [
    "---\n",
    "### Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1117cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned):\n",
    "    X_train_cleaned.to_csv('data/X_train_cleaned.csv', index=False)\n",
    "    y_train_cleaned.to_csv('data/y_train_cleaned.csv', index=False)\n",
    "    X_test_cleaned.to_csv('data/X_test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4947fde",
   "metadata": {},
   "source": [
    "---\n",
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e45364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X_train, y_train, contamination='auto', verbose=1):\n",
    "    \"\"\"\n",
    "    Remove the ouliers from our dataset. Temporarily replace the nan values by \n",
    "    the median to perform the outlier detection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.df\n",
    "        The features (what we will use to see the outliers)\n",
    "    y_train : pd.df\n",
    "        The labels\n",
    "    contamination : int, optional\n",
    "        The percent of outliers found by the isolation forest if it is used.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    (pd.df, pd.df)\n",
    "        The data with the outliers rows removed\n",
    "    \"\"\"\n",
    "    # Save a mask of the imputed values to be able to redo the imputation once the outlier detection is done\n",
    "    X_train_null_mask = X_train.isna()\n",
    "    \n",
    "    # Need to impute nan values for the outlier detection to work (cannot deal with nan)\n",
    "    X_train_imputed = pd.DataFrame(SimpleImputer(strategy=\"median\", verbose=verbose).fit_transform(X_train))\n",
    "    \n",
    "#     clf = IsolationForest(contamination=contamination, random_state=0) # modify here\n",
    "    clf = LocalOutlierFactor(contamination=contamination) # modify here\n",
    "    outliers_mask = pd.Series(clf.fit_predict(X_train_imputed))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Detected {(outliers_mask == -1).sum()} outliers, out of {outliers_mask.shape[0]} samples ({100 * (outliers_mask == -1).sum() / outliers_mask.shape[0]:.2f}%).\")\n",
    "    \n",
    "    # Put back the nan values\n",
    "    # convert the null mask to np.array so it is correctly applied since X_train indexes have changed\n",
    "    X_train_no_outliers = X_train_imputed.mask(np.array(X_train_null_mask))\n",
    "    \n",
    "    # Remove outliers from the training set\n",
    "    X_train_no_outliers = X_train_no_outliers.loc[outliers_mask == 1, :]\n",
    "    y_train_no_outliers = y_train.loc[outliers_mask == 1, :]\n",
    "    \n",
    "    return (X_train_no_outliers, y_train_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eaa6df",
   "metadata": {},
   "source": [
    "---\n",
    "### Data scaling\n",
    "Should be done as soon as possible because can have an effect (e.g. on distances for `KNNImputer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5091c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    # Do the scaling, saving the scaler to use it for X_test too. No need for imputation, just ignore nan values.\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "    # Cast X_test to np.array to avoid warning of model trained without feature names but X having some.\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(np.array(X_test)))\n",
    "    return (X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ca985",
   "metadata": {},
   "source": [
    "---\n",
    "### Imputation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e465756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(X_train, X_test):\n",
    "    print(f\"For the train dataset, there are {np.array(X_train_scaled.isna()).sum().sum()} nan values, out of {X_train_scaled.shape[0]*X_train_scaled.shape[1]} ({100*np.array(X_train_scaled.isna()).sum().sum()/(X_train_scaled.shape[0]*X_train_scaled.shape[1]):.2f}%).\")\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=6, weights='uniform').fit(X_train) # modify here\n",
    "    # Runs VERY slowly (i.e. did 1/10 of the job in 6 minutes...), need to tweak parameters\n",
    "#     imputer = IterativeImputer(random_state=0, verbose=2).fit(X_train) # modify here\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(imputer.transform(X_train))\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test))\n",
    "    return (X_train_imputed, X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684edef",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c1dd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "    X_train_selected_features, X_test_selected_features = remove_constant_features(X_train, X_test)\n",
    "    X_train_selected_features, X_test_selected_features = remove_too_correlated_features(X_train_selected_features, X_test_selected_features)\n",
    "    X_train_selected_features, X_test_selected_features = remove_random_features(X_train_selected_features, y_train, X_test_selected_features)\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31017dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_features(X_train, X_test, verbose=1):\n",
    "    X_train_selected_features = X_train.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    X_test_selected_features = X_test.loc[:, (X_train != X_train.iloc[0]).any()]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of constant values ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "    \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb3a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_correlated_features(X_train, X_test, threshold=0.8, verbose=1):\n",
    "    X_train_corr_ = X_train.corr()\n",
    "\n",
    "    X_train_too_correlated = (X_train_corr_.mask(\n",
    "        np.tril(np.ones([len(X_train_corr_)]*2, dtype=bool))).abs() > threshold).any()\n",
    "    \n",
    "    X_train_selected_features = X_train.loc[:, (~X_train_too_correlated)]\n",
    "    X_test_selected_features = X_test.loc[:, (~X_train_too_correlated)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of correlation > {threshold} ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "\n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb15cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_features(X_train, y_train, X_test, verbose=1):\n",
    "    selector = SelectPercentile(f_regression, percentile=80) # modify here\n",
    "    selector.fit(X_train, np.array(y_train).ravel())\n",
    "    X_train_selected_features = pd.DataFrame(selector.transform(X_train))\n",
    "    X_test_selected_features = pd.DataFrame(selector.transform(X_test))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{X_train.shape[1]-X_train_selected_features.shape[1]} features removed because of low correlation with target ({100*(X_train.shape[1]-X_train_selected_features.shape[1])/X_train.shape[1]:.2f}%)\")\n",
    "        \n",
    "    return X_train_selected_features, X_test_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a9b1a",
   "metadata": {},
   "source": [
    "---\n",
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0ea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lasso(X_train, y_train):\n",
    "    lasso = Lasso(max_iter=100000)\n",
    "    gs_lasso_params = {\n",
    "        'alpha': np.logspace(-1, 0, 20),\n",
    "    }\n",
    "    gs_lasso = GridSearchCV(lasso, gs_lasso_params, cv=5, verbose=3)\n",
    "    gs_lasso.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"The best validation score obtained is {gs_lasso.best_score_:.5f} with\\n\\talpha: {gs_lasso.best_params_['alpha']}\")\n",
    "    \n",
    "    return gs_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0634bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_svr(X_train, y_train):\n",
    "    svr = SVR()\n",
    "    gs_svr_params = {\n",
    "        'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "        'C': np.logspace(-1, 2.2, 4),\n",
    "        'epsilon': np.logspace(-2, 1, 3),\n",
    "    }\n",
    "    gs_svr = GridSearchCV(svr, gs_svr_params, cv=5, verbose=3)\n",
    "    gs_svr.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\"\"The best validation score obtained is {gs_svr.best_score_:.5f} with\n",
    "    \\tkernel: {gs_svr.best_params_['kernel']}\n",
    "    \\tC: {gs_svr.best_params_['C']}\n",
    "    \\tepsilon: {gs_svr.best_params_['epsilon']}\"\"\")\n",
    "    \n",
    "    return gs_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46b2b4bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_gbr(X_train, y_train):\n",
    "#     gbr = GradientBoostingRegressor(random_state=0)\n",
    "#     gs_gbr_params = {\n",
    "#         \"learning_rate\": np.logspace(-3, -1, 3),\n",
    "#         \"n_estimators\": np.logspace(1, 3, 3),\n",
    "#         \"subsample\": [0.7, 1],\n",
    "#         \"max_depth\": [3, 4, 5],\n",
    "#     }\n",
    "#     gs_gbr = GridSearchCV(gbr, gs_gbr_params, cv=5, verbose=3, error_score='raise')\n",
    "#     gs_gbr.fit(X_train, y_train)\n",
    "#     return gs_gbr\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"loss\": \"squared_error\",\n",
    "        \"random_state\": 0, \n",
    "        \"verbose\": 2,\n",
    "    }\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(**params)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Score is {gbr.score(X_test, y_test):.4f}.\")\n",
    "    \n",
    "    test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
    "        test_score[i] = gbr.loss_(y_test, y_pred)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(\"Deviance\")\n",
    "    plt.plot(\n",
    "        np.arange(params[\"n_estimators\"]) + 1,\n",
    "        gbr.train_score_,\n",
    "        \"b-\",\n",
    "        label=\"Training Set Deviance\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Boosting Iterations\")\n",
    "    plt.ylabel(\"Deviance\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad8547",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5efbec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(prediction, sub_id, basepath='submissions/task1-sub'):\n",
    "    result = prediction.copy()\n",
    "    result = result.rename(columns={0: 'y'})\n",
    "    result['id'] = range(0, len(result))\n",
    "    result = result[['id', 'y']]\n",
    "    result.to_csv(basepath + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc0755",
   "metadata": {},
   "source": [
    "---\n",
    "##Â Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2355bf",
   "metadata": {},
   "source": [
    "---\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76e24a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Removing outliers...\n",
      "Detected 50 outliers, out of 1212 samples (4.13%).\n",
      "Scaling data...\n",
      "Imputing nan values...\n",
      "For the train dataset, there are 73743 nan values, out of 966784 (7.63%).\n",
      "Selecting features...\n",
      "4 features removed because of constant values (0.48%)\n",
      "87 features removed because of correlation > 0.8 (10.51%)\n",
      "149 features removed because of low correlation with target (20.11%)\n",
      "Exporting clean data to csv...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw data...\")\n",
    "X_train, y_train, X_test = load_raw_data()\n",
    "\n",
    "print(\"Removing outliers...\")\n",
    "X_train_no_outliers, y_train_no_outliers = remove_outliers(X_train, y_train)\n",
    "\n",
    "print(\"Scaling data...\")\n",
    "X_train_scaled, X_test_scaled = scale(X_train_no_outliers, X_test)\n",
    "\n",
    "print(\"Imputing nan values...\")\n",
    "X_train_imputed, X_test_imputed = impute_values(X_train_scaled, X_test_scaled)\n",
    "\n",
    "print(\"Selecting features...\")\n",
    "X_train_selected_features, X_test_selected_features = select_features(X_train_imputed, y_train_no_outliers, X_test_imputed)\n",
    "\n",
    "print(\"Exporting clean data to csv...\")\n",
    "X_train_cleaned, y_train_cleaned, X_test_cleaned = X_train_selected_features, y_train_no_outliers, X_test_selected_features\n",
    "export_to_csv(X_train_cleaned, y_train_cleaned, X_test_cleaned)\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a4ed8",
   "metadata": {},
   "source": [
    "---\n",
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = best_lasso(X_train_cleaned, y_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6d465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr = best_svr(X_train_cleaned, np.array(y_train_cleaned).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab54dc2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          96.1602            1.30m\n",
      "         2          95.1053            1.29m\n",
      "         3          94.0713            1.27m\n",
      "         4          93.0620            1.26m\n",
      "         5          92.0668            1.26m\n",
      "         6          91.0684            1.25m\n",
      "         7          90.0973            1.25m\n",
      "         8          89.1688            1.28m\n",
      "         9          88.2340            1.27m\n",
      "        10          87.3144            1.27m\n",
      "        11          86.3989            1.26m\n",
      "        12          85.5015            1.26m\n",
      "        13          84.6056            1.25m\n",
      "        14          83.7414            1.25m\n",
      "        15          82.8941            1.25m\n",
      "        16          82.0438            1.25m\n",
      "        17          81.2263            1.24m\n",
      "        18          80.4096            1.24m\n",
      "        19          79.6227            1.24m\n",
      "        20          78.8357            1.23m\n",
      "        21          78.0527            1.23m\n",
      "        22          77.2937            1.23m\n",
      "        23          76.5070            1.22m\n",
      "        24          75.7414            1.24m\n",
      "        25          75.0091            1.24m\n",
      "        26          74.2656            1.25m\n",
      "        27          73.5406            1.24m\n",
      "        28          72.8172            1.24m\n",
      "        29          72.0946            1.23m\n",
      "        30          71.3815            1.23m\n",
      "        31          70.7123            1.24m\n",
      "        32          70.0168            1.25m\n",
      "        33          69.3243            1.25m\n",
      "        34          68.6572            1.24m\n",
      "        35          67.9961            1.24m\n",
      "        36          67.3479            1.24m\n",
      "        37          66.7265            1.23m\n",
      "        38          66.0981            1.23m\n",
      "        39          65.4882            1.23m\n",
      "        40          64.8936            1.23m\n",
      "        41          64.2769            1.23m\n",
      "        42          63.7134            1.23m\n",
      "        43          63.1078            1.23m\n",
      "        44          62.5200            1.23m\n",
      "        45          61.9346            1.22m\n",
      "        46          61.3736            1.22m\n",
      "        47          60.8072            1.21m\n",
      "        48          60.2538            1.22m\n",
      "        49          59.7434            1.22m\n",
      "        50          59.2133            1.22m\n",
      "        51          58.6812            1.21m\n",
      "        52          58.1602            1.21m\n",
      "        53          57.6354            1.21m\n",
      "        54          57.1254            1.21m\n",
      "        55          56.6217            1.21m\n",
      "        56          56.1312            1.21m\n",
      "        57          55.6408            1.21m\n",
      "        58          55.1820            1.21m\n",
      "        59          54.7158            1.21m\n",
      "        60          54.2422            1.20m\n",
      "        61          53.7716            1.20m\n",
      "        62          53.3268            1.20m\n",
      "        63          52.8737            1.20m\n",
      "        64          52.4486            1.19m\n",
      "        65          52.0084            1.19m\n",
      "        66          51.5711            1.18m\n",
      "        67          51.1650            1.18m\n",
      "        68          50.7707            1.18m\n",
      "        69          50.3545            1.17m\n",
      "        70          49.9455            1.17m\n",
      "        71          49.5617            1.17m\n",
      "        72          49.1717            1.16m\n",
      "        73          48.7805            1.16m\n",
      "        74          48.4009            1.15m\n",
      "        75          48.0142            1.15m\n",
      "        76          47.6364            1.15m\n",
      "        77          47.2621            1.14m\n",
      "        78          46.9151            1.14m\n",
      "        79          46.5531            1.14m\n",
      "        80          46.1874            1.13m\n",
      "        81          45.8420            1.13m\n",
      "        82          45.5007            1.13m\n",
      "        83          45.1639            1.12m\n",
      "        84          44.8259            1.12m\n",
      "        85          44.4842            1.12m\n",
      "        86          44.1604            1.11m\n",
      "        87          43.8246            1.11m\n",
      "        88          43.5150            1.11m\n",
      "        89          43.1894            1.10m\n",
      "        90          42.8728            1.10m\n",
      "        91          42.5716            1.10m\n",
      "        92          42.2634            1.09m\n",
      "        93          41.9671            1.09m\n",
      "        94          41.6705            1.09m\n",
      "        95          41.3851            1.08m\n",
      "        96          41.0888            1.08m\n",
      "        97          40.7938            1.08m\n",
      "        98          40.5065            1.07m\n",
      "        99          40.2490            1.07m\n",
      "       100          39.9751            1.07m\n",
      "       101          39.7154            1.06m\n",
      "       102          39.4387            1.06m\n",
      "       103          39.1456            1.06m\n",
      "       104          38.8859            1.05m\n",
      "       105          38.6203            1.05m\n",
      "       106          38.3479            1.05m\n",
      "       107          38.0905            1.05m\n",
      "       108          37.8308            1.04m\n",
      "       109          37.5612            1.04m\n",
      "       110          37.3391            1.04m\n",
      "       111          37.0901            1.03m\n",
      "       112          36.8371            1.03m\n",
      "       113          36.5825            1.03m\n",
      "       114          36.3471            1.02m\n",
      "       115          36.0860            1.02m\n",
      "       116          35.8372            1.02m\n",
      "       117          35.6125            1.02m\n",
      "       118          35.3750            1.01m\n",
      "       119          35.1262            1.01m\n",
      "       120          34.8925            1.01m\n",
      "       121          34.6695            1.00m\n",
      "       122          34.4284            1.00m\n",
      "       123          34.2091           59.87s\n",
      "       124          33.9686           59.69s\n",
      "       125          33.7500           59.52s\n",
      "       126          33.5447           59.33s\n",
      "       127          33.3133           59.18s\n",
      "       128          33.0902           58.99s\n",
      "       129          32.8682           58.82s\n",
      "       130          32.6517           58.64s\n",
      "       131          32.4433           58.49s\n",
      "       132          32.2255           58.34s\n",
      "       133          32.0149           58.21s\n",
      "       134          31.8131           58.07s\n",
      "       135          31.6273           57.94s\n",
      "       136          31.4220           57.75s\n",
      "       137          31.2212           57.60s\n",
      "       138          31.0293           57.41s\n",
      "       139          30.8414           57.25s\n",
      "       140          30.6608           57.07s\n",
      "       141          30.4784           56.94s\n",
      "       142          30.2957           56.75s\n",
      "       143          30.1113           56.58s\n",
      "       144          29.9286           56.39s\n",
      "       145          29.7590           56.22s\n",
      "       146          29.5848           56.04s\n",
      "       147          29.4181           55.87s\n",
      "       148          29.2503           55.69s\n",
      "       149          29.0766           55.52s\n",
      "       150          28.9048           55.34s\n",
      "       151          28.7389           55.17s\n",
      "       152          28.5577           54.99s\n",
      "       153          28.4091           54.83s\n",
      "       154          28.2498           54.65s\n",
      "       155          28.0917           54.48s\n",
      "       156          27.9253           54.30s\n",
      "       157          27.7733           54.13s\n",
      "       158          27.6243           53.96s\n",
      "       159          27.4766           53.80s\n",
      "       160          27.3223           53.63s\n",
      "       161          27.1770           53.47s\n",
      "       162          27.0198           53.29s\n",
      "       163          26.8568           53.13s\n",
      "       164          26.7237           52.95s\n",
      "       165          26.5808           52.80s\n",
      "       166          26.4412           52.62s\n",
      "       167          26.2970           52.46s\n",
      "       168          26.1708           52.28s\n",
      "       169          26.0135           52.15s\n",
      "       170          25.8740           51.98s\n",
      "       171          25.7264           51.81s\n",
      "       172          25.6101           51.65s\n",
      "       173          25.4738           51.50s\n",
      "       174          25.3355           51.33s\n",
      "       175          25.2040           51.17s\n",
      "       176          25.0701           51.00s\n",
      "       177          24.9441           50.84s\n",
      "       178          24.8215           50.67s\n",
      "       179          24.7107           50.51s\n",
      "       180          24.5869           50.33s\n",
      "       181          24.4513           50.17s\n",
      "       182          24.3319           50.00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       183          24.1945           49.84s\n",
      "       184          24.0719           49.67s\n",
      "       185          23.9524           49.51s\n",
      "       186          23.8374           49.35s\n",
      "       187          23.7352           49.20s\n",
      "       188          23.6220           49.03s\n",
      "       189          23.5073           48.87s\n",
      "       190          23.3969           48.71s\n",
      "       191          23.2875           48.55s\n",
      "       192          23.1649           48.38s\n",
      "       193          23.0638           48.21s\n",
      "       194          22.9348           48.04s\n",
      "       195          22.8262           47.88s\n",
      "       196          22.7087           47.72s\n",
      "       197          22.6157           47.56s\n",
      "       198          22.5091           47.39s\n",
      "       199          22.4075           47.24s\n",
      "       200          22.3037           47.08s\n",
      "       201          22.1957           46.92s\n",
      "       202          22.1026           46.75s\n",
      "       203          22.0025           46.59s\n",
      "       204          21.8857           46.42s\n",
      "       205          21.7811           46.26s\n",
      "       206          21.6670           46.09s\n",
      "       207          21.5575           45.93s\n",
      "       208          21.4561           45.76s\n",
      "       209          21.3459           45.59s\n",
      "       210          21.2478           45.44s\n",
      "       211          21.1487           45.28s\n",
      "       212          21.0668           45.11s\n",
      "       213          20.9569           44.95s\n",
      "       214          20.8559           44.78s\n",
      "       215          20.7625           44.62s\n",
      "       216          20.6623           44.46s\n",
      "       217          20.5681           44.30s\n",
      "       218          20.4709           44.13s\n",
      "       219          20.3839           43.97s\n",
      "       220          20.2933           43.81s\n",
      "       221          20.1946           43.65s\n",
      "       222          20.1084           43.48s\n",
      "       223          20.0206           43.32s\n",
      "       224          19.9250           43.16s\n",
      "       225          19.8382           43.00s\n",
      "       226          19.7324           42.84s\n",
      "       227          19.6452           42.67s\n",
      "       228          19.5499           42.51s\n",
      "       229          19.4668           42.35s\n",
      "       230          19.3819           42.19s\n",
      "       231          19.2861           42.03s\n",
      "       232          19.1893           41.87s\n",
      "       233          19.1141           41.71s\n",
      "       234          19.0145           41.54s\n",
      "       235          18.9350           41.39s\n",
      "       236          18.8546           41.23s\n",
      "       237          18.7666           41.07s\n",
      "       238          18.6683           40.91s\n",
      "       239          18.5845           40.76s\n",
      "       240          18.5070           40.59s\n",
      "       241          18.4294           40.43s\n",
      "       242          18.3540           40.27s\n",
      "       243          18.2748           40.12s\n",
      "       244          18.1944           39.96s\n",
      "       245          18.1012           39.80s\n",
      "       246          18.0279           39.64s\n",
      "       247          17.9346           39.48s\n",
      "       248          17.8442           39.31s\n",
      "       249          17.7742           39.15s\n",
      "       250          17.6998           39.00s\n",
      "       251          17.6295           38.84s\n",
      "       252          17.5584           38.68s\n",
      "       253          17.4863           38.52s\n",
      "       254          17.4142           38.36s\n",
      "       255          17.3462           38.20s\n",
      "       256          17.2677           38.04s\n",
      "       257          17.1886           37.88s\n",
      "       258          17.1085           37.72s\n",
      "       259          17.0329           37.56s\n",
      "       260          16.9606           37.40s\n",
      "       261          16.8855           37.26s\n",
      "       262          16.8093           37.09s\n",
      "       263          16.7507           36.94s\n",
      "       264          16.6739           36.78s\n",
      "       265          16.5958           36.62s\n",
      "       266          16.5239           36.47s\n",
      "       267          16.4570           36.31s\n",
      "       268          16.3892           36.15s\n",
      "       269          16.3190           36.00s\n",
      "       270          16.2441           35.84s\n",
      "       271          16.1780           35.68s\n",
      "       272          16.1093           35.52s\n",
      "       273          16.0551           35.37s\n",
      "       274          15.9899           35.21s\n",
      "       275          15.9258           35.06s\n",
      "       276          15.8592           34.90s\n",
      "       277          15.7935           34.75s\n",
      "       278          15.7314           34.59s\n",
      "       279          15.6720           34.43s\n",
      "       280          15.6014           34.27s\n",
      "       281          15.5394           34.12s\n",
      "       282          15.4756           33.96s\n",
      "       283          15.4169           33.81s\n",
      "       284          15.3557           33.65s\n",
      "       285          15.2956           33.49s\n",
      "       286          15.2243           33.33s\n",
      "       287          15.1575           33.18s\n",
      "       288          15.0886           33.01s\n",
      "       289          15.0283           32.86s\n",
      "       290          14.9680           32.70s\n",
      "       291          14.9044           32.55s\n",
      "       292          14.8398           32.39s\n",
      "       293          14.7723           32.23s\n",
      "       294          14.7148           32.07s\n",
      "       295          14.6512           31.91s\n",
      "       296          14.5844           31.75s\n",
      "       297          14.5330           31.60s\n",
      "       298          14.4784           31.44s\n",
      "       299          14.4162           31.29s\n",
      "       300          14.3710           31.13s\n",
      "       301          14.3104           30.97s\n",
      "       302          14.2505           30.82s\n",
      "       303          14.1964           30.66s\n",
      "       304          14.1372           30.50s\n",
      "       305          14.0769           30.35s\n",
      "       306          14.0240           30.19s\n",
      "       307          13.9639           30.04s\n",
      "       308          13.9119           29.88s\n",
      "       309          13.8501           29.72s\n",
      "       310          13.7923           29.59s\n",
      "       311          13.7399           29.44s\n",
      "       312          13.6926           29.29s\n",
      "       313          13.6433           29.15s\n",
      "       314          13.5778           28.98s\n",
      "       315          13.5224           28.83s\n",
      "       316          13.4660           28.67s\n",
      "       317          13.4030           28.51s\n",
      "       318          13.3481           28.35s\n",
      "       319          13.2905           28.20s\n",
      "       320          13.2291           28.04s\n",
      "       321          13.1797           27.89s\n",
      "       322          13.1256           27.73s\n",
      "       323          13.0686           27.57s\n",
      "       324          13.0231           27.41s\n",
      "       325          12.9695           27.26s\n",
      "       326          12.9060           27.10s\n",
      "       327          12.8580           26.96s\n",
      "       328          12.8128           26.80s\n",
      "       329          12.7607           26.66s\n",
      "       330          12.7295           26.51s\n",
      "       331          12.6860           26.36s\n",
      "       332          12.6299           26.20s\n",
      "       333          12.5777           26.04s\n",
      "       334          12.5173           25.88s\n",
      "       335          12.4741           25.73s\n",
      "       336          12.4241           25.57s\n",
      "       337          12.3960           25.42s\n",
      "       338          12.3460           25.26s\n",
      "       339          12.2929           25.10s\n",
      "       340          12.2465           24.95s\n",
      "       341          12.2112           24.79s\n",
      "       342          12.1659           24.64s\n",
      "       343          12.1185           24.48s\n",
      "       344          12.0675           24.32s\n",
      "       345          12.0325           24.17s\n",
      "       346          12.0059           24.01s\n",
      "       347          11.9620           23.86s\n",
      "       348          11.9258           23.70s\n",
      "       349          11.8732           23.55s\n",
      "       350          11.8401           23.39s\n",
      "       351          11.8143           23.24s\n",
      "       352          11.7659           23.08s\n",
      "       353          11.7163           22.92s\n",
      "       354          11.6744           22.77s\n",
      "       355          11.6304           22.61s\n",
      "       356          11.5981           22.46s\n",
      "       357          11.5518           22.30s\n",
      "       358          11.5272           22.14s\n",
      "       359          11.4935           21.99s\n",
      "       360          11.4509           21.83s\n",
      "       361          11.4038           21.68s\n",
      "       362          11.3619           21.52s\n",
      "       363          11.3204           21.37s\n",
      "       364          11.2969           21.22s\n",
      "       365          11.2531           21.06s\n",
      "       366          11.2141           20.91s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       367          11.1741           20.75s\n",
      "       368          11.1334           20.59s\n",
      "       369          11.1106           20.44s\n",
      "       370          11.0875           20.29s\n",
      "       371          11.0579           20.13s\n",
      "       372          11.0158           19.98s\n",
      "       373          10.9768           19.82s\n",
      "       374          10.9448           19.67s\n",
      "       375          10.9027           19.51s\n",
      "       376          10.8647           19.35s\n",
      "       377          10.8148           19.20s\n",
      "       378          10.7931           19.04s\n",
      "       379          10.7722           18.89s\n",
      "       380          10.7441           18.73s\n",
      "       381          10.7015           18.58s\n",
      "       382          10.6643           18.42s\n",
      "       383          10.6237           18.26s\n",
      "       384          10.5954           18.11s\n",
      "       385          10.5605           17.95s\n",
      "       386          10.5397           17.80s\n",
      "       387          10.5056           17.64s\n",
      "       388          10.4611           17.49s\n",
      "       389          10.4290           17.33s\n",
      "       390          10.3895           17.17s\n",
      "       391          10.3661           17.02s\n",
      "       392          10.3419           16.86s\n",
      "       393          10.3032           16.72s\n",
      "       394          10.2690           16.56s\n",
      "       395          10.2296           16.41s\n",
      "       396          10.2106           16.25s\n",
      "       397          10.1817           16.10s\n",
      "       398          10.1442           15.94s\n",
      "       399          10.1124           15.79s\n",
      "       400          10.0888           15.63s\n",
      "       401          10.0567           15.48s\n",
      "       402          10.0199           15.32s\n",
      "       403           9.9847           15.16s\n",
      "       404           9.9466           15.02s\n",
      "       405           9.9154           14.87s\n",
      "       406           9.8832           14.72s\n",
      "       407           9.8652           14.57s\n",
      "       408           9.8444           14.42s\n",
      "       409           9.8024           14.27s\n",
      "       410           9.7681           14.12s\n",
      "       411           9.7420           13.97s\n",
      "       412           9.7116           13.82s\n",
      "       413           9.6763           13.67s\n",
      "       414           9.6539           13.52s\n",
      "       415           9.6205           13.36s\n",
      "       416           9.5990           13.21s\n",
      "       417           9.5589           13.06s\n",
      "       418           9.5319           12.91s\n",
      "       419           9.5102           12.75s\n",
      "       420           9.4841           12.60s\n",
      "       421           9.4503           12.45s\n",
      "       422           9.4217           12.29s\n",
      "       423           9.3984           12.13s\n",
      "       424           9.3724           11.98s\n",
      "       425           9.3455           11.82s\n",
      "       426           9.3156           11.67s\n",
      "       427           9.2840           11.51s\n",
      "       428           9.2676           11.35s\n",
      "       429           9.2327           11.19s\n",
      "       430           9.2134           11.04s\n",
      "       431           9.1816           10.88s\n",
      "       432           9.1529           10.72s\n",
      "       433           9.1260           10.56s\n",
      "       434           9.0989           10.40s\n",
      "       435           9.0768           10.25s\n",
      "       436           9.0488           10.09s\n",
      "       437           9.0252            9.93s\n",
      "       438           9.0044            9.77s\n",
      "       439           8.9742            9.62s\n",
      "       440           8.9438            9.46s\n",
      "       441           8.9034            9.30s\n",
      "       442           8.8836            9.14s\n",
      "       443           8.8556            8.98s\n",
      "       444           8.8283            8.83s\n",
      "       445           8.8107            8.68s\n",
      "       446           8.7840            8.52s\n",
      "       447           8.7578            8.36s\n",
      "       448           8.7267            8.20s\n",
      "       449           8.7008            8.05s\n",
      "       450           8.6717            7.89s\n",
      "       451           8.6568            7.73s\n",
      "       452           8.6416            7.58s\n",
      "       453           8.6188            7.42s\n",
      "       454           8.5836            7.26s\n",
      "       455           8.5648            7.10s\n",
      "       456           8.5452            6.94s\n",
      "       457           8.5223            6.79s\n",
      "       458           8.5040            6.64s\n",
      "       459           8.4760            6.49s\n",
      "       460           8.4505            6.34s\n",
      "       461           8.4361            6.18s\n",
      "       462           8.4141            6.02s\n",
      "       463           8.3897            5.86s\n",
      "       464           8.3751            5.71s\n",
      "       465           8.3502            5.55s\n",
      "       466           8.3273            5.39s\n",
      "       467           8.3003            5.23s\n",
      "       468           8.2861            5.08s\n",
      "       469           8.2630            4.92s\n",
      "       470           8.2458            4.76s\n",
      "       471           8.2291            4.60s\n",
      "       472           8.2047            4.44s\n",
      "       473           8.1843            4.29s\n",
      "       474           8.1568            4.13s\n",
      "       475           8.1351            3.97s\n",
      "       476           8.1249            3.81s\n",
      "       477           8.1083            3.65s\n",
      "       478           8.0863            3.50s\n",
      "       479           8.0604            3.34s\n",
      "       480           8.0369            3.18s\n",
      "       481           8.0154            3.02s\n",
      "       482           7.9926            2.86s\n",
      "       483           7.9695            2.70s\n",
      "       484           7.9537            2.54s\n",
      "       485           7.9392            2.38s\n",
      "       486           7.9180            2.22s\n",
      "       487           7.8875            2.07s\n",
      "       488           7.8641            1.91s\n",
      "       489           7.8404            1.75s\n",
      "       490           7.8190            1.59s\n",
      "       491           7.8058            1.43s\n",
      "       492           7.7824            1.27s\n",
      "       493           7.7699            1.11s\n",
      "       494           7.7515            0.95s\n",
      "       495           7.7295            0.79s\n",
      "       496           7.7076            0.64s\n",
      "       497           7.6814            0.48s\n",
      "       498           7.6625            0.32s\n",
      "       499           7.6401            0.16s\n",
      "       500           7.6281            0.00s\n",
      "Score is 0.5767.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbr = best_gbr(X_train_cleaned, np.array(y_train_cleaned).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50adc0",
   "metadata": {},
   "source": [
    "---\n",
    "### Creation of the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc13d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(gbr.predict(X_test_selected_features)) # modify here\n",
    "sub_id = 8 # modify here\n",
    "create_submission(prediction, sub_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9cc0a",
   "metadata": {},
   "source": [
    "Link where to submit: https://aml.ise.inf.ethz.ch/task1/#submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
